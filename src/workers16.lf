target Python {
  coordination: decentralized
}

preamble {=
  import time
  import numpy as np
  import pyarrow.plasma as plasma
  session = plasma.connect("/tmp/plasma")
  import pickle

  def serialization(session, data):
      buffer = []
      pickled_data = pickle.dumps(data, protocol=5, buffer_callback=buffer.append)
      data_object_id = session.put(pickled_data)

      # Store memoryview in Plasma
      mem_view = buffer[0].raw()
      buffer_id = plasma.ObjectID.from_random()
      data_size = len(mem_view)

      # Create an object in Plasma and copy the memoryview data into it
      plasma_object = session.create(buffer_id, data_size)
      plasma_view = memoryview(plasma_object).cast('B')
      plasma_view[:] = mem_view[:]

      session.seal(buffer_id)

      # Return
      return [data_object_id, buffer_id]

  def deserialization(session, data_object_id, buffer_id):
      #memory getting
      buffer = session.get_buffers([buffer_id])
      pickled_data = session.get(data_object_id)
      data = pickle.loads(pickled_data, buffers=buffer)
      return data
=}

reactor clientReactor(STP_offset = 10000 s) {
  input global_parameters
  output updated_parameters

  reaction(startup) {=  =}

  reaction(global_parameters) -> updated_parameters {=
    data_pair = global_parameters.value
    val = deserialization(session, data_pair[0], data_pair[1])
    time.sleep(0.5)
    new_parameter = val.copy()
    id  = serialization(session, new_parameter)
    updated_parameters.set(id)
  =}
}

reactor serverReactor(STP_offset = 10000 s) {
  output global_parameters
  input[16] updated_parameters
  state round_num
  state benchmark_start_time
  state total_start_time

  reaction(startup) -> global_parameters {=
    self.round_num = 0
    self.results = [0] * 16
    self.benchmark_start_time = None
    self.total_start_time = None
    val = np.ones(1310720)
    id  = serialization(session, val)
    global_parameters.set(id)
  =}

  reaction(updated_parameters) -> global_parameters {=
    # Retrieve value from each client
    for i in range(16):
        data_pair = updated_parameters[i].value
        self.results[i] = deserialization(session, data_pair[0], data_pair[1])

    # Check and set the benchmark start time for the first round
    if self.round_num == 0:
        self.benchmark_start_time = time.time()
        self.total_start_time = time.time()

    if self.round_num == 1000:
        request_stop()

    # Calculate the overhead time difference for the current round and reset the start time for the next round
    current_time = time.time()
    overhead_time = current_time - self.benchmark_start_time - 0.5
    training_time = current_time - self.total_start_time
    self.benchmark_start_time = current_time

    # Print the overhead time and round number
    print(f"Round: {self.round_num}")
    print(f"Total training time: {training_time:.4f} seconds")
    print(f"Overhead: {overhead_time:.4f} seconds \n")

    self.round_num += 1

    # Update the global parameters with the results from the first client for the next round
    id = serialization(session, self.results[0].copy())
    global_parameters.set(id)
  =}
}

federated reactor {
  client = new[16] clientReactor()
  server = new serverReactor()
  (server.global_parameters)+ -> client.global_parameters after 0
  client.updated_parameters -> server.updated_parameters
}
